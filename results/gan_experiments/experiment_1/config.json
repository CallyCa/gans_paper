{
    "settings": {
        "seed": 655,
        "codings_size": 185,
        "batch_size": 64,
        "learning_rate": 0.000228
    },
    "gan": {
        "generator_layers": [
            {
                "units": 484,
                "activation": "relu",
                "kernel_initializer": "he_normal",
                "dropout": 0.27,
                "batch_normalization": true
            },
            {
                "units": 860,
                "activation": "leaky_relu",
                "kernel_initializer": "he_normal",
                "dropout": null,
                "batch_normalization": true
            },
            {
                "units": 494,
                "activation": "relu",
                "kernel_initializer": "he_normal",
                "dropout": 0.21,
                "batch_normalization": false
            },
            {
                "units": 481,
                "activation": "leaky_relu",
                "kernel_initializer": "lecun_normal",
                "dropout": 0.0,
                "batch_normalization": true
            }
        ],
        "discriminator_layers": [
            {
                "units": 688,
                "activation": "leaky_relu",
                "kernel_initializer": "glorot_uniform",
                "dropout": null,
                "batch_normalization": false
            },
            {
                "units": 360,
                "activation": "relu",
                "kernel_initializer": "glorot_uniform",
                "dropout": null,
                "batch_normalization": false
            },
            {
                "units": 874,
                "activation": "leaky_relu",
                "kernel_initializer": "he_normal",
                "dropout": 0.16,
                "batch_normalization": false
            },
            {
                "units": 336,
                "activation": "leaky_relu",
                "kernel_initializer": "glorot_uniform",
                "dropout": 0.21,
                "batch_normalization": true
            },
            {
                "units": 933,
                "activation": "relu",
                "kernel_initializer": "glorot_uniform",
                "dropout": 0.26,
                "batch_normalization": true
            },
            {
                "units": 645,
                "activation": "leaky_relu",
                "kernel_initializer": "glorot_uniform",
                "dropout": 0.11,
                "batch_normalization": false
            }
        ],
        "learning_rate": 0.000171,
        "epochs": 15,
        "loss_function": "binary_crossentropy",
        "optimizer": "rmsprop",
        "beta_1": 0.781,
        "beta_2": 0.968,
        "rho": 0.77
    }
}